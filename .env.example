# Apex Brain Configuration
# Copy this file to .env and fill in your values.
# (config.py checks both .env and apex_brain/.env for flexibility)

# ─── AI Model ──────────────────────────────────────────────────
# Change this string to swap providers instantly (via LiteLLM).
# Examples: gpt-4o, gpt-4o-mini, gpt-4-turbo
#           claude-sonnet-4-20250514, claude-opus-4-20250514
#           gemini/gemini-2.0-flash
# Full list: https://docs.litellm.ai/docs/providers
LITELLM_MODEL=gpt-4o

# ─── API Keys ──────────────────────────────────────────────────
# Only fill in the key for your chosen model provider.
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# ─── Memory & Embeddings ──────────────────────────────────────
# Embedding model for semantic memory search (OpenAI embeddings API)
EMBEDDING_MODEL=text-embedding-3-small

# Cheap model for background fact extraction after each conversation
FACT_EXTRACTION_MODEL=gpt-4o-mini

# How many recent conversation turns to include in context
RECENT_TURNS=10

# Max semantic facts to inject into the system prompt
MAX_FACTS_IN_CONTEXT=20

# ─── Home Assistant Connection ─────────────────────────────────
# For local development: http://<YOUR_HA_IP>:8123
# Inside HA add-on: http://supervisor/core (auto-set by run.sh)
HA_URL=http://192.168.1.100:8123

# Long-lived access token from HA: Profile > Security > Create Token
# Inside HA add-on: not needed (SUPERVISOR_TOKEN is auto-injected)
HA_TOKEN=your_long_lived_access_token_here

# ─── Database ─────────────────────────────────────────────────
# For local development: ./apex.db (created automatically)
# Inside HA add-on: /data/apex.db (persistent Docker volume)
DB_PATH=./apex.db
